#ifndef _SPTAG_SPANN_EXTRAFILECONTROLLER_H_
#define _SPTAG_SPANN_EXTRAFILECONTROLLER_H_
#define USE_ASYNC_IO
// #define USE_FILE_DEBUG
#include "inc/Helper/KeyValueIO.h"
#include "inc/Core/Common/Dataset.h"
#include "inc/Core/VectorIndex.h"
#include "inc/Helper/ThreadPool.h"
#include "inc/Helper/AsyncFileReader.h"
#include "inc/Core/SPANN/Options.h"
#include <cstdlib>
#include <memory>
#include <atomic>
#include <mutex>
#include <shared_mutex>
#include <fcntl.h>
#include <tbb/concurrent_queue.h>
#include <tbb/concurrent_hash_map.h>
#include <list>
namespace SPTAG::SPANN {
    typedef std::int64_t AddressType;
    class FileIO : public Helper::KeyValueIO {
        class BlockController {
        private:
            char* m_filePath = nullptr;
            std::shared_ptr <Helper::DiskIO> m_fileHandle = nullptr;

            tbb::concurrent_queue<AddressType> m_blockAddresses;
            tbb::concurrent_queue<AddressType> m_blockAddresses_reserve;

            thread_local static int debug_fd;
            
            int64_t read_complete_vec = 0;
            int64_t read_submit_vec = 0;
            int64_t write_complete_vec = 0;
            int64_t write_submit_vec = 0;
            int64_t read_bytes_vec = 0;
            int64_t write_bytes_vec = 0;
            int64_t read_blocks_time_vec = 0;

            std::mutex m_initMutex;
            int m_numInitCalled = 0;

            int m_batchSize = 64;
            int m_preIOCompleteCount = 0;
            int64_t m_preIOBytes = 0;

            std::chrono::high_resolution_clock::time_point m_startTime;
            std::chrono::time_point<std::chrono::high_resolution_clock> m_preTime = std::chrono::high_resolution_clock::now();

            std::atomic<int64_t> m_batchReadTimes = 0;
            std::atomic<int64_t> m_batchReadTimeouts = 0;

            // static void Start(void* args);

            // static void FileIoLoop(void *arg);

            // static void FileIoCallback(bool success, void *cb_arg);

            // static void Stop(void* args);

        public:
            bool Initialize(SPANN::Options& p_opt, bool p_recovery);

            bool GetBlocks(AddressType* p_data, int p_size);

            bool ReleaseBlocks(AddressType* p_data, int p_size);

            bool ReadBlocks(AddressType* p_data, std::string* p_value, const std::chrono::microseconds &timeout, std::vector<Helper::AsyncReadRequest>* reqs);

            bool ReadBlocks(const std::vector<AddressType*>& p_data, std::vector<std::string>* p_value, const std::chrono::microseconds &timeout, std::vector<Helper::AsyncReadRequest>* reqs);

            bool ReadBlocks(const std::vector<AddressType*>& p_data, std::vector<Helper::PageBuffer<std::uint8_t>>& p_value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs);

            bool WriteBlocks(AddressType* p_data, int p_size, const std::string& p_value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs);

            bool IOStatistics();

            bool ShutDown();

            int RemainBlocks() {
                return (int)(m_blockAddresses.unsafe_size());
            };

            ErrorCode Checkpoint(std::string prefix) {
                std::string filename = prefix + "_blockpool";
                SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO: saving block pool\n");
                SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Reload reserved blocks!\n");
                AddressType currBlockAddress = 0;
                for (int count = 0; count < m_blockAddresses_reserve.unsafe_size(); count++) {
                    m_blockAddresses_reserve.try_pop(currBlockAddress);
                    m_blockAddresses.push(currBlockAddress);
                }
                SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Reload Finish!\n");
                SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Save blockpool To %s\n", filename.c_str());
                auto ptr = f_createIO();
                if (ptr == nullptr || !ptr->Initialize(filename.c_str(), std::ios::binary | std::ios::out)) return ErrorCode::FailedCreateFile;
                int blocks = RemainBlocks();
                IOBINARY(ptr, WriteBinary, sizeof(SizeType), (char*)&blocks);
                for (auto it = m_blockAddresses.unsafe_begin(); it != m_blockAddresses.unsafe_end(); it++) {
                    IOBINARY(ptr, WriteBinary, sizeof(AddressType), (char*)&(*it));
                }
                SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Save Finish!\n");
                return ErrorCode::Success;
            }

	        ErrorCode LoadBlockPool(std::string prefix, AddressType maxNumBlocks, bool allowinit) {
	            std::string blockfile = prefix + "_blockpool";
                if (allowinit && !fileexists(blockfile.c_str())) {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO::BlockController::Initialize blockpool\n");
                    for(AddressType i = 0; i < maxNumBlocks; i++) {
                        m_blockAddresses.push(i);
                    }
                } else {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO::BlockController::Load blockpool from %s\n", blockfile.c_str());
                    auto ptr = f_createIO();
                    if (ptr == nullptr || !ptr->Initialize(blockfile.c_str(), std::ios::binary | std::ios::in)) {
                        SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Cannot open the blockpool file: %s\n", blockfile.c_str());
    		            return ErrorCode::Fail;
                    }
                    int blocks;
		            IOBINARY(ptr, ReadBinary, sizeof(SizeType), (char*)&blocks);
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO::BlockController::Reading %d blocks to pool\n", blocks);
                    AddressType currBlockAddress = 0;
                    for (int i = 0; i < blocks; i++) {
                        IOBINARY(ptr, ReadBinary, sizeof(AddressType), (char*)&(currBlockAddress));
                        m_blockAddresses.push(currBlockAddress);
	                }    
    	        }
		        return ErrorCode::Success;
	        }
        };

        class LRUCache {
            int capacity;   // Page Num
            std::uint64_t size;
            std::list<SizeType> keys;  // Page Address
            std::unordered_map<SizeType, std::pair<std::string, std::list<SizeType>::iterator>> cache;    // Page Address -> Page Address in Cache
            std::mutex mu;
            int64_t queries;
            int64_t hits;

        public:
            LRUCache(int capacity) {
                this->capacity = capacity;
                this->size = 0;
                this->queries = 0;
                this->hits = 0;
            }

            bool get(SizeType key, void* value) {
                mu.lock();
                queries++;
                auto it = cache.find(key);
                if (it == cache.end()) {
                    mu.unlock();
                    return false;  // 如果键不存在，返回 -1
                }
                // 更新访问顺序，将该键移动到链表头部
                memcpy(value, it->second.first.data(), it->second.first.size());
                keys.splice(keys.begin(), keys, it->second.second);
                it->second.second = keys.begin();
                hits++;
                mu.unlock();
                return true;
            }

            bool put(SizeType key, void* value, int put_size) {
                mu.lock();
                auto it = cache.find(key);
                if (it != cache.end()) {
                    if (put_size > capacity) {
                        size -= it->second.first.size();
                        keys.erase(it->second.second);
                        cache.erase(it);
                        mu.unlock();
                        return false;
                    }
                    auto keys_it = it->second.second;
                    keys.splice(keys.begin(), keys, keys_it);
                    it->second.second = keys.begin();
                    keys_it = keys.begin();
                    auto delta_size = put_size - it->second.first.size();
                    while ((capacity - size) < delta_size && (keys.size() > 1)) {
                        auto last = keys.back();
                        auto it = cache.find(last);
                        size -= it->second.first.size();
                        cache.erase(it);
                        keys.pop_back();
                    }
                    it->second.first.resize(put_size);
                    memcpy(it->second.first.data(), value, put_size);
                    size += delta_size;
                    mu.unlock();
                    return true;
                }
                if (put_size > capacity) {
                    mu.unlock();
                    return false;
                }
                while (put_size > (capacity - size) && (!keys.empty())) {
                    auto last = keys.back();
                    auto it = cache.find(last);
                    size -= it->second.first.size();
                    cache.erase(it);
                    keys.pop_back();
                }
                auto keys_it = keys.insert(keys.begin(), key);
                cache.insert({key, {std::string((char*)value, put_size), keys_it}});
                size += put_size;
                mu.unlock();
                return true;
            }

            bool del(SizeType key) {
                mu.lock();
                auto it = cache.find(key);
                if (it == cache.end()) {
                    mu.unlock();
                    return false;  // 如果键不存在，返回 false
                }
                size -= it->second.first.size();
                keys.erase(it->second.second);
                cache.erase(it);
                mu.unlock();
                return true;
            }

            bool merge(SizeType key, void* value, AddressType merge_size) {
                mu.lock();
                // SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "LRUCache: merge size: %lld\n", merge_size);
                auto it = cache.find(key);
                if (it == cache.end()) {
                    // SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "LRUCache: merge key not found\n");
                    mu.unlock();
                    return false;  // 如果键不存在，返回 false
                }
                if (merge_size + it->second.first.size() > capacity) {
                    size -= it->second.first.size();
                    keys.erase(it->second.second);
                    cache.erase(it);
                    // SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "LRUCache: merge size exceeded\n");
                    mu.unlock();
                    return false;
                }
                keys.splice(keys.begin(), keys, it->second.second);
                it->second.second = keys.begin();
                while((capacity - size) < merge_size && (keys.size() > 1)) {
                    auto last = keys.back();
                    auto it = cache.find(last);
                    size -= it->second.first.size();
                    cache.erase(it);
                    keys.pop_back();
                }
                it->second.first.append((char*)value, merge_size);
                size += merge_size;
                // SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "LRUCache: merge success\n");
                mu.unlock();
                return true;
            }
            
            std::pair<int64_t, int64_t> get_stat() {
                return {queries, hits};
            }
        }; 

        class ShardedLRUCache {
            int shards;
            std::vector<LRUCache*> caches;
            SizeType hash(SizeType key) const {
                return key % shards;
            }
        public:
            ShardedLRUCache(int shards, int capacity) : shards(shards) {
                caches.resize(shards);
                for (int i = 0; i < shards; i++) {
                    caches[i] = new LRUCache(capacity / shards);
                }
                if (capacity % shards != 0) {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Warning, "LRUCache: capacity is not divisible by shards\n");
                }
            }

            ~ShardedLRUCache() {
                for (int i = 0; i < shards; i++) {
                    delete caches[i];
                }
            }

            bool get(SizeType key, void* value) {
                return caches[hash(key)]->get(key, value);
            }

            bool put(SizeType key, void* value, SizeType put_size) {
                return caches[hash(key)]->put(key, value, put_size);
            }

            bool del(SizeType key) {
                return caches[hash(key)]->del(key);
            }

            bool merge(SizeType key, void* value, AddressType merge_size) {
                return caches[hash(key)]->merge(key, value, merge_size);
            }

            std::pair<int64_t, int64_t> get_stat() {
                int64_t queries = 0, hits = 0;
                for (int i = 0; i < shards; i++) {
                    auto stat = caches[i]->get_stat();
                    queries += stat.first;
                    hits += stat.second;
                }
                return {queries, hits};
            }
        };

    public:
        FileIO(SPANN::Options& p_opt) {
            m_mappingPath = p_opt.m_spdkMappingPath;
            m_blockLimit = p_opt.m_postingPageLimit + p_opt.m_bufferLength + 1;
            m_bufferLimit = 1024;

            const char* fileIoUseLock = getenv(kFileIoUseLock);
            if(fileIoUseLock) {
                if(strcmp(fileIoUseLock, "True") == 0) {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO: Using lock\n");
                    m_fileIoUseLock = true;
                    const char* fileIoLockSize = getenv(kFileIoLockSize);
                    if(fileIoLockSize) {
                        m_fileIoLockSize = atoi(fileIoLockSize);
                    }
                    m_rwMutex = std::vector<std::shared_mutex>(m_fileIoLockSize);
                }
                else {
                    m_fileIoUseLock = false;
                }
            }
            else {
                m_fileIoUseLock = false;
            }
            const char* fileIoUseCache = getenv(kFileIoUseCache);
            if (fileIoUseCache) {
                if (strcmp(fileIoUseCache, "True") == 0) {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO: Using cache\n");
                    m_fileIoUseCache = true;
                }
                else {
                    m_fileIoUseCache = false;
                }
            }
            if (m_fileIoUseCache) {
                const char* fileIoCacheSize = getenv(kFileIoCacheSize);
                const char* fileIoCacheShards = getenv(kFileIoCacheShards);
                int capacity = kSsdFileIoDefaultCacheSize;
                int shards = kSsdFileIoDefaultCacheShards;
                if(fileIoCacheSize) {
                    capacity = atoi(fileIoCacheSize);
                } 
                if(fileIoCacheShards) {
                    shards = atoi(fileIoCacheShards);
                }
                m_pShardedLRUCache = new ShardedLRUCache(shards, capacity);
            }

            if (p_opt.m_recovery) {
                Load(p_opt.m_persistentBufferPath + "_blockmapping", 1024 * 1024, MaxSize);
		        SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Recovery load block mapping successfully!\n");
            } else if(fileexists(m_mappingPath.c_str())) {
                Load(m_mappingPath, 1024 * 1024, MaxSize);
		        SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Load block mapping successfully!\n");
            } else {
		        SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Initialize block mapping successfully!\n");
                m_pBlockMapping.Initialize(0, 1, 1024 * 1024, MaxSize);
            }
            for (int i = 0; i < m_bufferLimit; i++) {
                m_buffer.push((uintptr_t)(new AddressType[m_blockLimit]));
            }
            m_compactionThreadPool = std::make_shared<Helper::ThreadPool>();
            m_compactionThreadPool->init(1);

            if (!m_pBlockController.Initialize(p_opt, p_opt.m_recovery)) {
                SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Fail to Initialize FileIO!\n");
                exit(0);
            }

            m_shutdownCalled = false;
        }

        ~FileIO() {
            ShutDown();
        }

        void ShutDown() override {
            if (m_shutdownCalled) {
                return;
            }
            if (!m_mappingPath.empty()) Save(m_mappingPath);
            // TODO: 这里是不是应该加锁？
            for (int i = 0; i < m_pBlockMapping.R(); i++) {
                if (At(i) != 0xffffffffffffffff) delete[]((AddressType*)At(i));
            }
            while (!m_buffer.empty()) {
                uintptr_t ptr = 0xffffffffffffffff;
                if (m_buffer.try_pop(ptr)) delete[]((AddressType*)ptr);
            }
            m_pBlockController.ShutDown();
            if (m_fileIoUseCache) {
                delete m_pShardedLRUCache;
            }
            m_shutdownCalled = true;
        }

        inline uintptr_t& At(SizeType key) {
            return *(m_pBlockMapping[key]);
        }
        
        ErrorCode Get(const SizeType key, std::string* value, const std::chrono::microseconds &timeout, std::vector<Helper::AsyncReadRequest>* reqs) override {
            auto get_begin_time = std::chrono::high_resolution_clock::now();
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].lock_shared();
            }
            SizeType r;
            if (m_fileIoUseLock) {
                m_updateMutex.lock_shared();
                r = m_pBlockMapping.R();
                m_updateMutex.unlock_shared();
            }
            else {
                r = m_pBlockMapping.R();
            }
            if (key >= r) return ErrorCode::Fail;

            if (m_fileIoUseCache) {
                auto size = ((AddressType*)At(key))[0];
                value->resize(size);
                if (m_pShardedLRUCache->get(key, value->data())) {
                    if (m_fileIoUseLock) {
                        m_rwMutex[hash(key)].unlock_shared();
                    }
                    auto get_end_time = std::chrono::high_resolution_clock::now();
                    get_time_vec += std::chrono::duration_cast<std::chrono::microseconds>(get_end_time - get_begin_time).count();
                    return ErrorCode::Success;
                }
            }
            
            
            // if (m_pBlockController.ReadBlocks((AddressType*)At(key), value)) {
            //     return ErrorCode::Success;
            // }
            auto begin_time = std::chrono::high_resolution_clock::now();
            auto result = m_pBlockController.ReadBlocks((AddressType*)At(key), value, timeout, reqs);
            auto end_time = std::chrono::high_resolution_clock::now();
            read_time_vec += std::chrono::duration_cast<std::chrono::microseconds>(end_time - begin_time).count();
            get_times_vec++;
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].unlock_shared();
            }
            auto get_end_time = std::chrono::high_resolution_clock::now();
            get_time_vec += std::chrono::duration_cast<std::chrono::microseconds>(get_end_time - get_begin_time).count();
            return result ? ErrorCode::Success : ErrorCode::Fail;
        }

        ErrorCode Get(const std::string& key, std::string* value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs) override {
            return Get(std::stoi(key), value, timeout, reqs);
        }

        ErrorCode MultiGet(const std::vector<SizeType>& keys, std::vector<Helper::PageBuffer<std::uint8_t>>& values,
            const std::chrono::microseconds &timeout, std::vector<Helper::AsyncReadRequest>* reqs) override {
            std::vector<AddressType*> blocks;
            std::set<int> lock_keys;
            if (m_fileIoUseLock) {
                // 这里要去重？
                // for (SizeType key : keys) {
                //     lock_keys.insert(hash(key));
                // }
                for (SizeType key : keys) {
                    m_rwMutex[hash(key)].lock_shared();
                }
            }
            SizeType r;
            int i = 0;
            for (SizeType key : keys) {
                if (m_fileIoUseLock) {
                    m_updateMutex.lock_shared();
                    r = m_pBlockMapping.R();
                    m_updateMutex.unlock_shared();
                }
                else {
                    r = m_pBlockMapping.R();
                }
                if (key < r) {
                    if (m_fileIoUseCache) {
                        auto size = ((AddressType*)At(key))[0];
                        values[i].SetAvailableSize(size);
                        if (m_pShardedLRUCache->get(key, values[i].GetBuffer())) {
                            blocks.push_back(nullptr);
                        }
                        else {
                            blocks.push_back((AddressType*)At(key));
                        }
                    } else {
                        blocks.push_back((AddressType*)At(key));
                    }
                    
                }
                else {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Fail to read key:%d total key number:%d\n", key, r);
                }
                i++;
            }
            // if (m_pBlockController.ReadBlocks(blocks, values, timeout)) return ErrorCode::Success;
            auto result = m_pBlockController.ReadBlocks(blocks, values, timeout, reqs);
            if (m_fileIoUseLock) {
                for (SizeType key : keys) {
                    m_rwMutex[hash(key)].unlock_shared();
                }
            }
            return result ? ErrorCode::Success : ErrorCode::Fail;
        }


        ErrorCode MultiGet(const std::vector<SizeType>& keys, std::vector<std::string>* values,
            const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs) {
            std::vector<AddressType*> blocks;
            std::set<int> lock_keys;
            if (m_fileIoUseLock) {
                // 这里要去重？
                // for (SizeType key : keys) {
                //     lock_keys.insert(hash(key));
                // }
                for (SizeType key : keys) {
                    m_rwMutex[hash(key)].lock_shared();
                }
            }
            SizeType r;
            values->resize(keys.size());
            int i = 0;
            for (SizeType key : keys) {
                if (m_fileIoUseLock) {
                    m_updateMutex.lock_shared();
                    r = m_pBlockMapping.R();
                    m_updateMutex.unlock_shared();
                }
                else {
                    r = m_pBlockMapping.R();
                }
                if (key < r) {
                    if (m_fileIoUseCache) {
                        auto size = ((AddressType*)At(key))[0];
                        (*values)[i].resize(size);
                        if (m_pShardedLRUCache->get(key, (*values)[i].data())) {
                            blocks.push_back(nullptr);
                        }
                        else {
                            blocks.push_back((AddressType*)At(key));
                        }
                    }
                    else {
                        blocks.push_back((AddressType*)At(key));
                    }

                }
                else {
                    SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Fail to read key:%d total key number:%d\n", key, r);
                }
                i++;
            }
            // if (m_pBlockController.ReadBlocks(blocks, values, timeout)) return ErrorCode::Success;
            auto result = m_pBlockController.ReadBlocks(blocks, values, timeout, reqs);
            if (m_fileIoUseLock) {
                for (SizeType key : keys) {
                    m_rwMutex[hash(key)].unlock_shared();
                }
            }
            return result ? ErrorCode::Success : ErrorCode::Fail;
        }

        ErrorCode MultiGet(const std::vector<std::string>& keys, std::vector<std::string>* values, 
            const std::chrono::microseconds &timeout, std::vector<Helper::AsyncReadRequest>* reqs) override {
            std::vector<SizeType> int_keys;
            for (const auto& key : keys) {
                int_keys.push_back(std::stoi(key));
            }
            return MultiGet(int_keys, values, timeout, reqs);
        }

        /*
        ErrorCode Scan(const SizeType start_key, const int record_count, std::vector<ByteArray> &values, const std::chrono::microseconds &timeout = (std::chrono::microseconds::max)(), std::vector<Helper::AsyncReadRequest>* reqs = nullptr) {
            std::vector<SizeType> keys;
            std::vector<AddressType*> blocks;
            SizeType curr_key = start_key;
            while(keys.size() < record_count && curr_key < m_pBlockMapping.R()) {
                if (m_fileIoUseLock) {
                    m_rwMutex[hash(curr_key)].lock_shared();
                }
                if (At(curr_key) == 0xffffffffffffffff) {
                    if (m_fileIoUseLock) {
                        m_rwMutex[hash(curr_key)].unlock_shared();
                    }
                    curr_key++;
                    continue;
                }
                keys.push_back(curr_key);
                blocks.push_back((AddressType*)At(curr_key));
                curr_key++;
            }
            auto result = m_pBlockController.ReadBlocks(blocks, values, timeout, reqs);
            if (m_fileIoUseLock) {
                for (auto key : keys) {
                    m_rwMutex[hash(key)].unlock_shared();
                }
            }
            return result ? ErrorCode::Success : ErrorCode::Fail;
        }
        */

        ErrorCode Put(const SizeType key, const std::string& value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs) override {
            int blocks = (int)(((value.size() + PageSize - 1) >> PageSizeEx));
            if (blocks >= m_blockLimit) {
                SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Fail to put key:%d value:%lld since value too long!\n", key, value.size());
                return ErrorCode::Fail;
            }
            // 计算是否需要更多的Mapping块
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].lock();
            }
            int delta;
            if (m_fileIoUseLock) {
                m_updateMutex.lock_shared();
                delta = key + 1 - m_pBlockMapping.R();
                m_updateMutex.unlock_shared();
            }
            else {
                delta = key + 1 - m_pBlockMapping.R();
            }
            if (delta > 0) {
                // std::lock_guard<std::mutex> lock(m_updateMutex);
                m_updateMutex.lock();
                delta = key + 1 - m_pBlockMapping.R();
                if (delta > 0) {
                    m_pBlockMapping.AddBatch(delta);
                }
                m_updateMutex.unlock();
            }

            if (m_fileIoUseCache) {
                m_pShardedLRUCache->put(key, (void*)(value.data()), (SPTAG::SizeType)(value.size()));
            }

            // 如果这个key还没有分配过Mapping块，就分配一组
            if (At(key) == 0xffffffffffffffff) {
                // m_buffer里有多的块就直接用，没有就new一组
                if (m_buffer.unsafe_size() > m_bufferLimit) {
                    uintptr_t tmpblocks = 0xffffffffffffffff;
                    while (!m_buffer.try_pop(tmpblocks));
                    At(key) = tmpblocks;
                }
                else {
                    At(key) = (uintptr_t)(new AddressType[m_blockLimit]);
                }
                // 块地址列表里的0号元素代表数据大小，将其设为-1
                memset((AddressType*)At(key), -1, sizeof(AddressType) * m_blockLimit);
            }
            int64_t* postingSize = (int64_t*)At(key);
            // postingSize小于0说明是新分配的Mapping块，直接获取磁盘块，写入数据
            if (*postingSize < 0) {
                m_pBlockController.GetBlocks(postingSize + 1, blocks);
                m_pBlockController.WriteBlocks(postingSize + 1, blocks, value, timeout, reqs);
                *postingSize = value.size();
            }
            else {
                uintptr_t tmpblocks = 0xffffffffffffffff;
                // 从buffer里拿一组Mapping块，一会再还一组回去
                while (!m_buffer.try_pop(tmpblocks));
                // 获取一组新的磁盘块，直接写入数据
                // 为保证Checkpoint的效果，这里必须分配新的块进行写入
                m_pBlockController.GetBlocks((AddressType*)tmpblocks + 1, blocks);
                m_pBlockController.WriteBlocks((AddressType*)tmpblocks + 1, blocks, value, timeout, reqs);
                *((int64_t*)tmpblocks) = value.size();

                // 释放原有的块
                m_pBlockController.ReleaseBlocks(postingSize + 1, (*postingSize + PageSize - 1) >> PageSizeEx);
                At(key) = tmpblocks;
                m_buffer.push((uintptr_t)postingSize);
            }
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].unlock();
            }
            return ErrorCode::Success;
        }

        ErrorCode Put(const std::string &key, const std::string& value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs) override {
            return Put(std::stoi(key), value, timeout, reqs);
        }

        ErrorCode Merge(const SizeType key, const std::string& value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs) {
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].lock();
            }
            SizeType r;
            if (m_fileIoUseLock) {
                m_updateMutex.lock_shared();
                r = m_pBlockMapping.R();
                m_updateMutex.unlock_shared();
            }
            else {
                r = m_pBlockMapping.R();
            }
            if (key >= r) {
                SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Key range error: key: %d, mapping size: %d\n", key, r);
                if (m_fileIoUseLock) {
                    m_rwMutex[hash(key)].unlock();
                }
                return ErrorCode::Fail;
            }
            
            int64_t* postingSize = (int64_t*)At(key);

            if (m_fileIoUseCache) {
                m_pShardedLRUCache->merge(key, (void *)(value.data()), value.size());
            }

            auto newSize = *postingSize + value.size();
            int newblocks = ((newSize + PageSize - 1) >> PageSizeEx);
            if (newblocks >= m_blockLimit) {
                SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Failt to merge key:%d value:%lld since value too long!\n", key, newSize);
                SPTAGLIB_LOG(Helper::LogLevel::LL_Error, "Origin Size: %lld, merge size: %lld\n", *postingSize, value.size());
                if (m_fileIoUseLock) {
                    m_rwMutex[hash(key)].unlock();
                }
                return ErrorCode::Fail;
            }

            auto sizeInPage = (*postingSize) % PageSize;    // 最后一个块的实际大小
            int oldblocks = (*postingSize >> PageSizeEx);
            int allocblocks = newblocks - oldblocks;
            // 最后一个块没有写满的话，需要先读出来，然后拼接新的数据，再写回去
            if (sizeInPage != 0) {
                std::string newValue;
                AddressType readreq[] = { sizeInPage, *(postingSize + 1 + oldblocks) };
                m_pBlockController.ReadBlocks(readreq, &newValue, timeout, reqs);
                newValue += value;

                uintptr_t tmpblocks = 0xffffffffffffffff;
                while (!m_buffer.try_pop(tmpblocks));
                memcpy((AddressType*)tmpblocks, postingSize, sizeof(AddressType) * (oldblocks + 1));
                m_pBlockController.GetBlocks((AddressType*)tmpblocks + 1 + oldblocks, allocblocks);
                m_pBlockController.WriteBlocks((AddressType*)tmpblocks + 1 + oldblocks, allocblocks, newValue, timeout, reqs);
                *((int64_t*)tmpblocks) = newSize;

                // 这里也是为了保证Checkpoint，所以将原本没用满的块释放，分配一个新的
                m_pBlockController.ReleaseBlocks(postingSize + 1 + oldblocks, 1);
                At(key) = tmpblocks;
                m_buffer.push((uintptr_t)postingSize);
            }
            else {  // 否则直接分配一组块接在后面
                m_pBlockController.GetBlocks(postingSize + 1 + oldblocks, allocblocks);
                m_pBlockController.WriteBlocks(postingSize + 1 + oldblocks, allocblocks, value, timeout, reqs);
                *postingSize = newSize;
            }
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].unlock();
            }
            return ErrorCode::Success;
        }

        ErrorCode Merge(const std::string &key, const std::string& value, const std::chrono::microseconds& timeout, std::vector<Helper::AsyncReadRequest>* reqs) {
            return Merge(std::stoi(key), value, timeout, reqs);
        }

        ErrorCode Delete(SizeType key) override {
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].lock();
            }
            SizeType r;
            if (m_fileIoUseLock) {
                m_updateMutex.lock_shared();
                r = m_pBlockMapping.R();
                m_updateMutex.unlock_shared();
            }
            else {
                r = m_pBlockMapping.R();
            }
            if (key >= r) return ErrorCode::Fail;

            if (m_fileIoUseCache) {
                m_pShardedLRUCache->del(key);
            }

            int64_t* postingSize = (int64_t*)At(key);
            if (*postingSize < 0) {
                if (m_fileIoUseLock) {
                    m_rwMutex[hash(key)].unlock();
                }
                return ErrorCode::Fail;
            }

            int blocks = ((*postingSize + PageSize - 1) >> PageSizeEx);
            m_pBlockController.ReleaseBlocks(postingSize + 1, blocks);
            m_buffer.push((uintptr_t)postingSize);
            At(key) = 0xffffffffffffffff;
            if (m_fileIoUseLock) {
                m_rwMutex[hash(key)].unlock();
            }
            return ErrorCode::Success;
        }

        ErrorCode Delete(const std::string &key) {
            return Delete(std::stoi(key));
        }

        void ForceCompaction() {
            Save(m_mappingPath);
        }

        void GetStat() {
            int remainBlocks = m_pBlockController.RemainBlocks();
            int remainGB = (long long)remainBlocks << PageSizeEx >> 30;
            // int remainGB = remainBlocks >> 20 << 2;
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Remain %d blocks, totally %d GB\n", remainBlocks, remainGB);
            double average_read_time = (double)read_time_vec / get_times_vec;
            double average_get_time = (double)get_time_vec / get_times_vec;
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Get times: %llu, get time: %llu us, read time: %llu us\n", get_times_vec, get_time_vec, read_time_vec);
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Average read time: %lf us, average get time: %lf us\n", average_read_time, average_get_time);
            if (m_fileIoUseCache) {
                auto cache_stat = m_pShardedLRUCache->get_stat();
                SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Cache queries: %lld, Cache hits: %lld, Hit rates: %lf\n", cache_stat.first, cache_stat.second, cache_stat.second == 0 ? 0 : (double)cache_stat.second / cache_stat.first);
            }
            m_pBlockController.IOStatistics();
        }

        ErrorCode Load(std::string path, SizeType blockSize, SizeType capacity) {
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Load mapping From %s\n", path.c_str());
            auto ptr = f_createIO();
            if (ptr == nullptr || !ptr->Initialize(path.c_str(), std::ios::binary | std::ios::in)) return ErrorCode::FailedOpenFile;

            SizeType CR, mycols;
            IOBINARY(ptr, ReadBinary, sizeof(SizeType), (char*)&CR);
            IOBINARY(ptr, ReadBinary, sizeof(SizeType), (char*)&mycols);
            if (mycols > m_blockLimit) m_blockLimit = mycols;

            m_pBlockMapping.Initialize(CR, 1, blockSize, capacity);
            for (int i = 0; i < CR; i++) {
                At(i) = (uintptr_t)(new AddressType[m_blockLimit]);
                IOBINARY(ptr, ReadBinary, sizeof(AddressType) * mycols, (char*)At(i));
            }
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Load mapping (%d,%d) Finish!\n", CR, mycols);
            return ErrorCode::Success;
        }
        
        ErrorCode Save(std::string path) {
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Save mapping To %s\n", path.c_str());
            auto ptr = f_createIO();
            if (ptr == nullptr || !ptr->Initialize(path.c_str(), std::ios::binary | std::ios::out)) return ErrorCode::FailedCreateFile;

            SizeType CR = m_pBlockMapping.R();
            IOBINARY(ptr, WriteBinary, sizeof(SizeType), (char*)&CR);
            IOBINARY(ptr, WriteBinary, sizeof(SizeType), (char*)&m_blockLimit);
            std::vector<AddressType> empty(m_blockLimit, 0xffffffffffffffff);
            for (int i = 0; i < CR; i++) {
                if (At(i) == 0xffffffffffffffff) {
                    IOBINARY(ptr, WriteBinary, sizeof(AddressType) * m_blockLimit, (char*)(empty.data()));
                }
                else {
                    int64_t* postingSize = (int64_t*)At(i);
                    IOBINARY(ptr, WriteBinary, sizeof(AddressType) * m_blockLimit, (char*)postingSize);
                }
            }
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Save mapping (%d,%d) Finish!\n", CR, m_blockLimit);
            return ErrorCode::Success;
        }

        bool Initialize(bool debug = false) override {
            if (debug) SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Initialize FileIO for new threads\n");
            return true;
        }

        bool ExitBlockController(bool debug = false) override { 
            if (debug) SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "Exit FileIO for thread\n");
            return m_pBlockController.ShutDown(); 
        }

        ErrorCode Checkpoint(std::string prefix) override {
            std::string filename = prefix + "_blockmapping";
            SPTAGLIB_LOG(Helper::LogLevel::LL_Info, "FileIO: saving block mapping\n");
            Save(filename);
            return m_pBlockController.Checkpoint(prefix);
        }

    private:
        static constexpr const char* kFileIoUseLock = "SPFRESH_FILE_IO_USE_LOCK";
        static constexpr bool kFileIoDefaultUseLock = false;
        static constexpr const char* kFileIoLockSize = "SPFRESH_FILE_IO_LOCK_SIZE";
        static constexpr int kFileIoDefaultLockSize = 1024;
        static constexpr const char* kFileIoUseCache = "SPFRESH_FILE_IO_USE_CACHE";
        static constexpr bool kFileIoDefaultUseCache = false;
        static constexpr const char* kFileIoCacheSize = "SPFRESH_FILE_IO_CACHE_SIZE";
        static constexpr int kSsdFileIoDefaultCacheSize = 8192 << 10;
        static constexpr const char* kFileIoCacheShards = "SPFRESH_FILE_IO_CACHE_SHARDS";
        static constexpr int kSsdFileIoDefaultCacheShards = 4;

        uint64_t read_time_vec = 0;
        uint64_t get_time_vec = 0;
        uint64_t get_times_vec = 0;

        bool m_fileIoUseLock = kFileIoDefaultUseLock;
        int m_fileIoLockSize = kFileIoDefaultLockSize;
        bool m_fileIoUseCache = kFileIoDefaultUseCache;
        std::string m_mappingPath;
        SizeType m_blockLimit;
        COMMON::Dataset<uintptr_t> m_pBlockMapping;
        SizeType m_bufferLimit;
        tbb::concurrent_queue<uintptr_t> m_buffer;

        std::shared_ptr<Helper::ThreadPool> m_compactionThreadPool;
        BlockController m_pBlockController;
        ShardedLRUCache *m_pShardedLRUCache;

        bool m_shutdownCalled;
        std::shared_mutex m_updateMutex;
        std::vector<std::shared_mutex> m_rwMutex;

        inline int hash(int key) {
            return key % m_fileIoLockSize;
        }
    };
}
#endif
